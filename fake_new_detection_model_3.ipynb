{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "df = pd.read_csv('./news.csv') # Buka dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_column = [\"title\", \"text\",\"label\"]\n",
    "\n",
    "df_cleaned = df[selected_column].dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>American Dream, Revisited</td>\n",
       "      <td>Will Trump pull a Brexit times ten? What would it take, beyond WikiLeaks, to bring the Clinton (...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>Clintons Are Under Multiple FBI Investigations as Agents Are Stymied</td>\n",
       "      <td>Clintons Are Under Multiple FBI Investigations as Agents Are Stymied   Source: Wall street on pa...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>The FBI Can’t Actually Investigate a Candidate Such as Hillary Clinton.</td>\n",
       "      <td>Dispatches from Eric Zuesse This piece is crossposted at strategic-culture.org The power above t...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>Confirmed: Public overwhelmingly (10-to-1) says media want Hillary to win</td>\n",
       "      <td>Print \\n[Ed. – Every now and then the facade cracks. Somebody asks a question the media haven’t ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>Nanny In Jail After Force Feeding Baby To Death</td>\n",
       "      <td>Nanny In Jail After Force Feeding Baby To Death 2 shares by Ike Mclean / October 27, 2016 / LIFE...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          title  \\\n",
       "1357                                                  American Dream, Revisited   \n",
       "2080       Clintons Are Under Multiple FBI Investigations as Agents Are Stymied   \n",
       "2718    The FBI Can’t Actually Investigate a Candidate Such as Hillary Clinton.   \n",
       "812   Confirmed: Public overwhelmingly (10-to-1) says media want Hillary to win   \n",
       "4886                            Nanny In Jail After Force Feeding Baby To Death   \n",
       "\n",
       "                                                                                                     text  \\\n",
       "1357  Will Trump pull a Brexit times ten? What would it take, beyond WikiLeaks, to bring the Clinton (...   \n",
       "2080  Clintons Are Under Multiple FBI Investigations as Agents Are Stymied   Source: Wall street on pa...   \n",
       "2718  Dispatches from Eric Zuesse This piece is crossposted at strategic-culture.org The power above t...   \n",
       "812   Print \\n[Ed. – Every now and then the facade cracks. Somebody asks a question the media haven’t ...   \n",
       "4886  Nanny In Jail After Force Feeding Baby To Death 2 shares by Ike Mclean / October 27, 2016 / LIFE...   \n",
       "\n",
       "     label  \n",
       "1357  FAKE  \n",
       "2080  FAKE  \n",
       "2718  FAKE  \n",
       "812   FAKE  \n",
       "4886  FAKE  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6335, 3)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\62822\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\62822\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from langdetect import detect\n",
    "import string\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Download NLTK data if needed\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "porter = PorterStemmer()\n",
    "corpus = df_cleaned\n",
    "\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1357    Will Trump pull a Brexit times ten? What would it take, beyond WikiLeaks, to bring the Clinton (...\n",
       "2080    Clintons Are Under Multiple FBI Investigations as Agents Are Stymied   Source: Wall street on pa...\n",
       "2718    Dispatches from Eric Zuesse This piece is crossposted at strategic-culture.org The power above t...\n",
       "812     Print \\n[Ed. – Every now and then the facade cracks. Somebody asks a question the media haven’t ...\n",
       "4886    Nanny In Jail After Force Feeding Baby To Death 2 shares by Ike Mclean / October 27, 2016 / LIFE...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['text'].head() # Sebelum Casefolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1357    will trump pull a brexit times ten? what would it take, beyond wikileaks, to bring the clinton (...\n",
       "2080    clintons are under multiple fbi investigations as agents are stymied   source: wall street on pa...\n",
       "2718    dispatches from eric zuesse this piece is crossposted at strategic-culture.org the power above t...\n",
       "812     print \\n[ed. – every now and then the facade cracks. somebody asks a question the media haven’t ...\n",
       "4886    nanny in jail after force feeding baby to death 2 shares by ike mclean / october 27, 2016 / life...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['text'].apply(lambda x: x.lower()).head() # Setelah CaseFolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1357    Will Trump pull a Brexit times ten? What would it take, beyond WikiLeaks, to bring the Clinton (...\n",
       "2080    Clintons Are Under Multiple FBI Investigations as Agents Are Stymied   Source: Wall street on pa...\n",
       "2718    Dispatches from Eric Zuesse This piece is crossposted at strategic-culture.org The power above t...\n",
       "812     Print \\n[Ed. – Every now and then the facade cracks. Somebody asks a question the media haven’t ...\n",
       "4886    Nanny In Jail After Force Feeding Baby To Death 2 shares by Ike Mclean / October 27, 2016 / LIFE...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1357    will trump pull brexit times ten? what would take, beyond wikileaks, bring clinton (cash) machin...\n",
       "2080    clintons are under multiple fbi investigations agents are stymied   source: wall street parade \\...\n",
       "2718    dispatches eric zuesse this piece crossposted strategic-culture.org the power u.s. federal burea...\n",
       "812     print \\n[ed. – every facade cracks. somebody asks question media haven’t intervened spin yet, bi...\n",
       "4886    nanny in jail after force feeding baby to death 2 shares ike mclean / october 27, 2016 / life / ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['text'][: 10].apply(lambda x: ' '.join([word.lower() for word in x.split(' ') if word not in stop_words])).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1357    will trump pull brexit time ten? what would take, beyond wikileaks, bring clinton (cash) machin ...\n",
       "2080    clinton are under multipl fbi investig agent are stymi   source: wall street parad \\ndisgrac for...\n",
       "2718    dispatch eric zuess thi piec crosspost strategic-culture.org the power u.s. feder bureau investi...\n",
       "812     print \\n[ed. – everi facad cracks. somebodi ask question media haven’t interven spin yet, bit tr...\n",
       "4886    nanni in jail after forc feed babi to death 2 share ike mclean / octob 27, 2016 / life / \\nolure...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['text'][: 10].apply(lambda x: ' '.join([porter.stem(word.lower()) for word in x.split(' ') if word not in stop_words])).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1357    [will, trump, pull, brexit, time, ten, ?, what, would, take, ,, beyond, wikileaks, ,, bring, cli...\n",
       "2080    [clinton, are, under, multipl, fbi, investig, agent, are, stymi, source, :, wall, street, parad,...\n",
       "2718    [dispatch, eric, zuess, thi, piec, crosspost, strategic-culture.org, the, power, u.s., feder, bu...\n",
       "812     [print, [, ed, ., –, everi, facad, cracks, ., somebodi, ask, question, media, haven, ’, t, inter...\n",
       "4886    [nanni, in, jail, after, forc, feed, babi, to, death, 2, share, ike, mclean, /, octob, 27, ,, 20...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['text'][: 10].apply(lambda x: word_tokenize(' '.join([porter.stem(word.lower()) for word in x.split(' ') if word not in stop_words]))).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize, remove stopwords, and perform stemming\n",
    "preprocessed_corpus = []\n",
    "labels = []\n",
    "\n",
    "for index, row in corpus.iterrows():\n",
    "    words = word_tokenize(row['text'])\n",
    "    filtered_words = [porter.stem(word.lower()) for word in words if word.isalnum() and word.lower() not in stop_words]\n",
    "\n",
    "    # Only append to preprocessed_corpus if filtered_words is not empty\n",
    "    if filtered_words:\n",
    "        preprocessed_corpus.append(' '.join(filtered_words))\n",
    "        labels.append(row['label'])\n",
    "\n",
    "# Create a DataFrame for preprocessed text and labels\n",
    "result_df = pd.DataFrame({'text': preprocessed_corpus, 'label': labels})\n",
    "\n",
    "# Save the result DataFrame to CSV\n",
    "result_df.to_csv('preprocessed_corpus_with_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump pull brexit time ten would take beyond wikileak bring clinton cash machin hillari win decl...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinton multipl fbi investig agent stymi sourc wall street parad disgrac former congressman anth...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dispatch eric zuess piec crosspost power feder bureau investig fbi attorney gener person presid ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>print ed everi facad crack somebodi ask question media interven spin yet bit truth peek public r...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nanni jail forc feed babi death 2 share ike mclean octob 27 2016 life oluremi oyindasola 66 glen...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  trump pull brexit time ten would take beyond wikileak bring clinton cash machin hillari win decl...   \n",
       "1  clinton multipl fbi investig agent stymi sourc wall street parad disgrac former congressman anth...   \n",
       "2  dispatch eric zuess piec crosspost power feder bureau investig fbi attorney gener person presid ...   \n",
       "3  print ed everi facad crack somebodi ask question media interven spin yet bit truth peek public r...   \n",
       "4  nanni jail forc feed babi death 2 share ike mclean octob 27 2016 life oluremi oyindasola 66 glen...   \n",
       "\n",
       "  label  \n",
       "0  FAKE  \n",
       "1  FAKE  \n",
       "2  FAKE  \n",
       "3  FAKE  \n",
       "4  FAKE  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_corpus = pd.read_csv('./preprocessed_corpus_with_labels.csv', dtype=str)\n",
    "\n",
    "preprocessed_corpus.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yemen</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>zero</th>\n",
       "      <th>zika</th>\n",
       "      <th>zone</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03715</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.161350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         10  100   11   12   13   14   15   16   17   18  ...      year  \\\n",
       "0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.014132   \n",
       "1  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.041144   \n",
       "2  0.025978  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.007412   \n",
       "3  0.161350  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "4  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "\n",
       "   yemen  yesterday       yet      york  young      zero  zika     zone  label  \n",
       "0    0.0        0.0  0.000000  0.000000    0.0  0.036473   0.0  0.03715   FAKE  \n",
       "1    0.0        0.0  0.000000  0.066209    0.0  0.000000   0.0  0.00000   FAKE  \n",
       "2    0.0        0.0  0.034113  0.000000    0.0  0.000000   0.0  0.00000   FAKE  \n",
       "3    0.0        0.0  0.070627  0.000000    0.0  0.000000   0.0  0.00000   FAKE  \n",
       "4    0.0        0.0  0.000000  0.000000    0.0  0.000000   0.0  0.00000   FAKE  \n",
       "\n",
       "[5 rows x 2001 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Create the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=2000)\n",
    "\n",
    "# Fit and transform the preprocessed corpus\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(list(preprocessed_corpus['text']))\n",
    "\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.joblib')\n",
    "# Convert the TF-IDF matrix to a DataFrame (for better visualization)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names(), \n",
    "                        index=['Doc'+str(i+1) for i in range(preprocessed_corpus.shape[0])])\n",
    "\n",
    "# Reset indices before concatenating\n",
    "preprocessed_corpus.reset_index(drop=True, inplace=True)\n",
    "tfidf_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Concatenate TF-IDF DataFrame with the label column\n",
    "result_df = pd.concat([tfidf_df, preprocessed_corpus['label']], axis=1)\n",
    "\n",
    "result_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>ye</th>\n",
       "      <th>year</th>\n",
       "      <th>yemen</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>zero</th>\n",
       "      <th>zika</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.161350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         10  100   11   12   13   14   15   16   17   18  ...   ye      year  \\\n",
       "0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.014132   \n",
       "1  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.041144   \n",
       "2  0.025978  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.007412   \n",
       "3  0.161350  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
       "4  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.000000   \n",
       "\n",
       "   yemen  yesterday       yet      york  young      zero  zika     zone  \n",
       "0    0.0        0.0  0.000000  0.000000    0.0  0.036473   0.0  0.03715  \n",
       "1    0.0        0.0  0.000000  0.066209    0.0  0.000000   0.0  0.00000  \n",
       "2    0.0        0.0  0.034113  0.000000    0.0  0.000000   0.0  0.00000  \n",
       "3    0.0        0.0  0.070627  0.000000    0.0  0.000000   0.0  0.00000  \n",
       "4    0.0        0.0  0.000000  0.000000    0.0  0.000000   0.0  0.00000  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transform the preprocessed corpus\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(list(preprocessed_corpus['text']))\n",
    "\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming result_df is your DataFrame with preprocessed text, TF-IDF features, and labels\n",
    "X = result_df.drop('label', axis=1)  # Features (TF-IDF)\n",
    "y = result_df['label'].replace({\"REAL\": 0, \"FAKE\": 1}).T.groupby(level=0).last().T # Labels\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.85\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84       641\n",
      "           1       0.81      0.90      0.85       619\n",
      "\n",
      "    accuracy                           0.85      1260\n",
      "   macro avg       0.85      0.85      0.85      1260\n",
      "weighted avg       0.85      0.85      0.85      1260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "knn_classification_report = classification_report(y_test, knn_predictions)\n",
    "\n",
    "print(f'KNN Accuracy: {knn_accuracy:.2f}')\n",
    "print('KNN Classification Report:')\n",
    "print(knn_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.911111\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       641\n",
      "           1       0.90      0.92      0.91       619\n",
      "\n",
      "    accuracy                           0.91      1260\n",
      "   macro avg       0.91      0.91      0.91      1260\n",
      "weighted avg       0.91      0.91      0.91      1260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "# Misalkan model Anda disimpan dalam variabel 'svm_model'\n",
    "\n",
    "\n",
    "# Create SVM model\n",
    "svm_model = SVC(kernel='linear')  # You can adjust the kernel type (linear, polynomial, etc.)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(svm_model, 'svm_model.joblib')\n",
    "# Make predictions on the test set\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy, precision, recall, and F1-score for SVM\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "svm_classification_report = classification_report(y_test, svm_predictions)\n",
    "\n",
    "print(f'SVM Accuracy: {svm_accuracy:.6f}')\n",
    "print('SVM Classification Report:')\n",
    "print(svm_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.900794\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90       641\n",
      "           1       0.89      0.91      0.90       619\n",
      "\n",
      "    accuracy                           0.90      1260\n",
      "   macro avg       0.90      0.90      0.90      1260\n",
      "weighted avg       0.90      0.90      0.90      1260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create Logistic Regression model\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy, precision, recall, and F1-score for Logistic Regression\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "lr_classification_report = classification_report(y_test, lr_predictions)\n",
    "\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy:.6f}')\n",
    "print('Logistic Regression Classification Report:')\n",
    "print(lr_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\62822\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\Users\\62822\\anaconda3\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:49:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost Accuracy: 0.93\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93       641\n",
      "           1       0.92      0.93      0.92       619\n",
      "\n",
      "    accuracy                           0.93      1260\n",
      "   macro avg       0.93      0.93      0.93      1260\n",
      "weighted avg       0.93      0.93      0.93      1260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create XGBoost model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy, precision, recall, and F1-score for XGBoost\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_predictions)\n",
    "xgb_classification_report = classification_report(y_test, xgb_predictions)\n",
    "\n",
    "print(f'XGBoost Accuracy: {xgb_accuracy:.2f}')\n",
    "print('XGBoost Classification Report:')\n",
    "print(xgb_classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
